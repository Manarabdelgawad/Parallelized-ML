# -*- coding: utf-8 -*-
"""Untitled21.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1chyHpU0iLmw9c07-Rqn-5WszgknBshtg

# **Parallelized Machine Learning Pipeline for Lung Cancer Prediction**
"""

# import required libraries
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.feature_selection import SelectPercentile, chi2
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from multiprocessing import Manager, Process, Pool, Queue
import threading
import os

#  Load Data function

def load_data(file_path, queue):
    print(f"Loading data... (Thread: {threading.current_thread().name}, Process ID: {os.getpid()})")
    df = pd.read_csv(file_path)
    queue.put(df)

#  Preprocess Data function (Label Encoding & Imputation)

def preprocess_data(X_shared, shape, queue):
    print(f"Preprocessing data... (Thread: {threading.current_thread().name}, Process ID: {os.getpid()})")

    X = np.array(X_shared).reshape(shape)
    l = LabelEncoder()
    X[:, 0] = l.fit_transform(X[:, 0])
    X[:, -1] = l.fit_transform(X[:, -1])
    imputer = SimpleImputer(strategy='mean')
    X[:] = imputer.fit_transform(X)
    queue.put(X)

#  Feature Selection function

def feature_selection(X_shared, shape, y, queue):
    print(f"Feature selection... (Thread: {threading.current_thread().name}, Process ID: {os.getpid()})")
    X = np.array(X_shared).reshape(shape)
    fs = SelectPercentile(score_func=chi2, percentile=80)
    X_selected = fs.fit_transform(X, y)
    queue.put(X_selected)
    print("Feature Selection Completed.")

#  Train Models function

def train_model(model_name, X_train, X_test, y_train, y_test):
    print(f"Training {model_name} (Thread: {threading.current_thread().name}, Process ID: {os.getpid()})\n")
    try:
        if model_name == "SVC":
            model = SVC(kernel="rbf", gamma=0.5, C=1.0)
        else:
            model = RandomForestClassifier(n_estimators=15)
        model.fit(X_train, y_train)
        pred = model.predict(X_test)
        acc = accuracy_score(y_test, pred)
        prec = precision_score(y_test, pred, pos_label=1)
        rec = recall_score(y_test, pred, pos_label=1)
        f1 = f1_score(y_test, pred, pos_label=1)
        print(f"{model_name} - Accuracy: {acc:.2f}, Precision: {prec:.2f}, Recall: {rec:.2f}, F1-Score: {f1:.2f}")
        return (model_name, acc, prec, rec, f1)
    except Exception as e:
        print(f"Training failed for {model_name}: {e}")
        return (model_name, 0, 0, 0, 0)

#  Main program -------------------------------------------------------------------
if __name__ == "__main__":
    file_path = "/content/drive/MyDrive/lung cancer.csv"

    # Using Queue to Commnuication between process
    data_queue = Queue()

    # --- Multi-threaded Data Loading ---
    threads = []
    for i in range(3):  # Simulate multiple threads loading data
        thread = threading.Thread(target=load_data, args=(file_path, data_queue), name=f"LoaderThread-{i+1}")
        threads.append(thread)
        thread.start()

    for thread in threads:
        thread.join()
    print("Data Loaded.")

    if not data_queue.empty():
        df = data_queue.get()
    else:
        print("Data loading failed.")
        exit()

    X = df.drop('LUNG_CANCER', axis=1).values
    y = df['LUNG_CANCER'].values

    le_y = LabelEncoder()
    y = le_y.fit_transform(y)
    # Shared data between processes using array
    X = pd.DataFrame(X).apply(pd.to_numeric, errors='coerce').fillna(0).values
    shape = X.shape

   # Shared data between processes using Server memory

    with Manager() as manager:
        X_shared = manager.Array('d', X.flatten())
        preprocess_queue = Queue()
        feature_queue = Queue()

        # --- Multi-threaded Preprocessing ---
        threads = []
        for i in range(3):
            thread = threading.Thread(target=preprocess_data, args=(X_shared, shape, preprocess_queue),)
            threads.append(thread)
            thread.start()

        for thread in threads:
            thread.join()
        print("Preprocessing Completed.")


        if not preprocess_queue.empty():
            X = preprocess_queue.get()

        # --- Multiprocessing for Feature Selection ---
        p1 = Process(target=feature_selection, args=(X_shared, shape, y, feature_queue))
        p1.start()
        p1.join()

        if not feature_queue.empty():
            X_selected = feature_queue.get()
        else:
            print("Feature selection failed.")
            X_selected = X

        X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)
        # using Pooling to divided task on 4 cpu
        pool = Pool(processes=4)
        results = [
            pool.apply_async(train_model, args=("SVC", X_train, X_test, y_train, y_test)),
            pool.apply_async(train_model, args=("RandomForest", X_train, X_test, y_train, y_test)),
        ]

        pool.close()
        pool.join()

        print("Collecting results from pool...")
        for result in results:
            result.get()